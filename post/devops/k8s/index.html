<!DOCTYPE html>
<html>

    <head>
        <title> k8s 使用方法 &amp; 备忘 &middot; trainyao.github.io </title>

        <meta http-equiv="content-type" content="text/html; charset=utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
<meta name="generator" content="Hugo 0.82.0" />




<script src="https://code.jquery.com/jquery-3.1.1.min.js"   integrity="sha256-hVVnYaiADRTO2PzUGmuLJr8BLUSjGIZsDYGmIJLv2b8="   crossorigin="anonymous"></script>


<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">

<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>


<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.2/css/all.css" integrity="sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr" crossorigin="anonymous">


<link rel="stylesheet" href="https://trainyao.github.io/css/nix.css">





<link href="https://fonts.googleapis.com/css?family=Inconsolata%7COpen+Sans%7CConcert+One" rel="stylesheet">






    </head>

    <body>
        <header>
<nav class="navbar navbar-default navbar-fixed-top navbar-inverse font-header">
	<div class="container-fluid">
		<div class="navbar-header">
			<button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar-collapse-1" aria-expanded="false">
				<span class="sr-only">Toggle navigation</span>
				<span class="icon-bar"></span>
				<span class="icon-bar"></span>
				<span class="icon-bar"></span>
			</button>
      <a class="navbar-brand" id="green-terminal" href='https://trainyao.github.io/'>
        trainyao@home ~ $
      </a>
		</div>

		
		<div class="collapse navbar-collapse" id="navbar-collapse-1">
			<ul class="nav navbar-nav navbar-right">
				<li>
					<a href='https://trainyao.github.io/'>/home/trainyao</a>
        </li>
        
				
				
				<li class="dropdown">
                    
            		<a href="https://trainyao.github.io/post/">~/post</a>
            		
        		</li>
        		
				
				<li class="dropdown">
                    
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">category <span class="caret"></span></a>
                    <ul class="dropdown-menu">
                        
                    		<li>
                    		<a href="https://trainyao.github.io/categories/kubernetes/">~/kubernetes</a>
				    		</li>
                		
                    		<li>
                    		<a href="https://trainyao.github.io/categories/devops/">~/devops</a>
				    		</li>
                		
                    		<li>
                    		<a href="https://trainyao.github.io/categories/istio/">~/service mesh/istio</a>
				    		</li>
                		
                    		<li>
                    		<a href="https://trainyao.github.io/categories/gloo/">~/service mesh/envoy/gloo</a>
				    		</li>
                		
                    		<li>
                    		<a href="https://trainyao.github.io/categories/mosn/">~/service mesh/mosn</a>
				    		</li>
                		
                    		<li>
                    		<a href="https://trainyao.github.io/categories/skynet/">~/skynet</a>
				    		</li>
                		
                    		<li>
                    		<a href="https://trainyao.github.io/categories/%E8%84%91%E6%B4%9E/">~/脑洞</a>
				    		</li>
                		
                    		<li>
                    		<a href="https://trainyao.github.io/categories/%E5%85%B6%E4%BB%96/">~/其他</a>
				    		</li>
                		
                    		<li>
                    		<a href="https://trainyao.github.io/categories/%E7%BF%BB%E8%AF%91/">~/翻译</a>
				    		</li>
                		
                    		<li>
                    		<a href="https://trainyao.github.io/categories/kubernetes-%E6%9D%83%E5%A8%81%E6%8C%87%E5%8D%97/">~/读书笔记/kubernetes 权威指南</a>
				    		</li>
                		
                    		<li>
                    		<a href="https://trainyao.github.io/categories/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/">~/读书笔记/深入理解计算机系统</a>
				    		</li>
                		
            		</ul>
            		
        		</li>
        		

			</ul>
		</div>
	</div>
</nav>
</header>

        <div class="flex-wrapper">
            <div class="container wrapper">
                <h1><a href="https://trainyao.github.io/post/devops/k8s/">k8s 使用方法 &amp; 备忘</a></h1>
                <span class="post-date">0001-01-01 </span>
                <div class="post-content">
                    <h1 id="安装">安装</h1>
<h2 id="使用-kubeadm">使用 kubeadm</h2>
<p>ref <a href="https://www.cnblogs.com/xiao987334176/p/12696740.html">https://www.cnblogs.com/xiao987334176/p/12696740.html</a></p>
<h2 id="安装-kubeadm-kubectl-kubelet">安装 kubeadm, kubectl, kubelet</h2>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">apt-get install apt-transport-https ca-certificates curl gnupg lsb-release

curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg

echo <span style="color:#e6db74">&#34;deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu \
</span><span style="color:#e6db74"></span><span style="color:#66d9ef">$(</span>lsb_release -cs<span style="color:#66d9ef">)</span><span style="color:#e6db74"> stable&#34;</span> | sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null

curl -fsSLo /usr/share/keyrings/kubernetes-archive-keyring.gpg https://packages.cloud.google.com/apt/doc/apt-key.gpg

echo <span style="color:#e6db74">&#34;deb [signed-by=/usr/share/keyrings/kubernetes-archive-keyring.gpg] https://apt.kubernetes.io/ kubernetes-xenial main&#34;</span> | sudo tee /etc/apt/sources.list.d/kubernetes.list

apt-get install docker-ce docker-ce-cli containerd.io
</code></pre></div><h3 id="初始化-master-worker-节点">初始化 master worker 节点</h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubeadm init --kubernetes-version<span style="color:#f92672">=</span>1.18.1 --apiserver-advertise-address<span style="color:#f92672">=</span>192.168.128.130 --image-repository registry.aliyuncs.com/google_containers  --service-cidr<span style="color:#f92672">=</span>10.1.0.0/16  --pod-network-cidr<span style="color:#f92672">=</span>10.244.0.0/16
              <span style="color:#e6db74">```</span>
<span style="color:#75715e">### 安装 flannel</span>
<span style="color:#e6db74">```</span>shell
wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml <span style="color:#f92672">&amp;&amp;</span> grep 10.244 -n kube-flannel.yml <span style="color:#f92672">&amp;&amp;</span> sed -i <span style="color:#e6db74">&#39;s/10.244.0.0\/16/[pod network cidr]/&#39;</span> <span style="color:#f92672">&amp;&amp;</span> kubectl apply -f kube-flannel.yml
</code></pre></div><h1 id="cni">cni</h1>
<h2 id="cni-插件工作原理">cni 插件工作原理</h2>
<ul>
<li>init config to /etc/cni/net.d/<em>-</em>.conflist</li>
<li>kubelet 内的 CRI 实现, dockershim 加载配置文件</li>
<li>kubelet 根据配置文件, 依次调用 CNI 插件, 初始化 pause 容器, 配置容器网络</li>
</ul>
<h2 id="细节">细节</h2>
<ul>
<li>hairpin mode, 配置 cni 网桥 veth 设备接收数据包的功能, 确保容器可以在容器网络里访问自己</li>
</ul>
<h2 id="plugins">plugins</h2>
<ul>
<li>plugins 都依照 <a href="https://github.com/containernetworking/cni/tree/master/pkg/skel">containernetworking/cni/skel</a> 做基本框架</li>
<li>bridge
<ul>
<li>source code <a href="https://github.com/containernetworking/plugins/blob/master/plugins/main/bridge/bridge.go">containernetworking/plugins/bridge</a>
- 依托 lib <a href="https://github.com/vishvananda/netlink">github.com/vishvananda/netlink</a> 做 ip link add/set 命令操作</li>
</ul>
</li>
<li>cilium (v1.9.8)
<ul>
<li>
<p>安装</p>
<ul>
<li>安装过程颇容易, 官网有提供 operator 直接一键安装 <code>kubectl apply -f https://raw.githubusercontent.com/cilium/cilium/v1.9/install/kubernetes/quick-install.yaml -n kube-system</code> <a href="https://docs.cilium.io/en/v1.9/gettingstarted/k8s-install-default/">官方 install doc</a></li>
<li>前置依赖
<ul>
<li>挂在 bpf 目录 <code>sudo mount bpffs /sys/fs/bpf -t bpf &amp;&amp; echo 'bpffs        /sys/fs/bpf      bpf     defaults 0 0' &gt;&gt; /etc/fstab</code></li>
<li>打开内核 cilium 依赖的关于 bpf 的参数 via <code>/boot/config-$(uname -r)</code> 参考<a href="https://docs.cilium.io/en/v1.9/operations/system_requirements/#linux-kernel">官方文档描述</a>, master ubuntu-18.04, kernel 4.15.0-143-generic, worker node ubuntu-18.04, kernel 5.4.0-74-generic</li>
</ul>
<pre><code>  CONFIG_BPF=y
  CONFIG_BPF_SYSCALL=y
  CONFIG_NET_CLS_BPF=y
  CONFIG_BPF_JIT=y
  CONFIG_NET_CLS_ACT=y
  CONFIG_NET_SCH_INGRESS=y
  CONFIG_CRYPTO_SHA1=y
  CONFIG_CRYPTO_USER_API_HASH=y
  CONFIG_CGROUPS=y
  CONFIG_CGROUP_BPF=y
  ```
</code></pre></li>
</ul>
</li>
<li>
<p>调试</p>
<ul>
<li><a href="https://docs.cilium.io/en/v1.9/gettingstarted/k8s-install-default/#deploy-the-connectivity-test">官方提供的连接测试用例</a> <code>kubectl create ns cilium-test &amp;&amp; kubectl apply -f https://raw.githubusercontent.com/cilium/cilium/v1.9/examples/kubernetes/connectivity-check/connectivity-check.yaml -n cilium-test</code></li>
<li>其他博主调整过的用例 <code>kubectl apply -n cilium-test -f https://github.com/nevermosby/K8S-CNI-Cilium-Tutorial/raw/master/cilium/connectivity-check.yaml</code> 参考<a href="https://cilium.io/blog/2020/05/04/guest-blog-kubernetes-cilium">博文</a>
<ul>
<li>可以使用不同主机上的 pod 互相访问 测试联通性, <code>docker run --rm trainyao/toolbox:ubuntu-18-40 -- ping [pod IP from other worker]</code></li>
</ul>
</li>
</ul>
</li>
<li>
<p>压测</p>
<ul>
<li>压测数据 (千兆网卡)
<ul>
<li>iperf 测得 <code>907Mbyte/s</code></li>
<li>siege -c 100 -t 2M
<ul>
<li>测得 service 访问 pod 4k qps 左右, 1.79M/s 吞吐量</li>
<li>测得 headless service 访问 pod 4k qps 左右, 2M/s 吞吐量</li>
<li>测得不同节点 pod ip qps 4k qps 左右, 3M/s 吞吐量</li>
</ul>
</li>
</ul>
</li>
<li>和 flannel 对比
<ul>
<li>cilium 换 flannel 过程中还发现 flannel daemonest 会报 <code>fail to configure interface flannel.1 address already in use</code>, 重启节点之后就好了, 怀疑是因为 cilium 配置过宿主机的网卡之类的, 重启之后配置重置过了</li>
<li>iperf 测得 <code>910Mbyte/s</code></li>
<li>siege -c 100 -t 2M
<ul>
<li>测得 service 访问 pod 4k qps 左右, 4M/s 吞吐量</li>
<li>测得 headless service 访问 pod 4k qps 左右, 4M/s 吞吐量</li>
<li>测得不同节点 pod ip qps 5k qps 左右, 3M/s 吞吐量</li>
</ul>
</li>
</ul>
</li>
<li><code>TODO</code> 怀疑可能是节点规模没上去, iptable / eBPF 差距应该没这么大? 待验证</li>
</ul>
</li>
<li>
<p>源码/原理研究</p>
<ul>
<li>初始化
<ul>
<li>利用 bpf/init.sh 初始化 cilium 的 eBPF 程序, ebpf 程序源码在 <a href="https://github.com/cilium/cilium/tree/v1.9.8/bpf">bpf/<em>.c bpf/</em>.h</a>
<ul>
<li>bpf/init.sh 在 daemon.go daemon_main.go 里执行, (grep bpf/init.sh)</li>
<li>bpf程序将整个流量处理的逻辑写成c程序, 并在 bpf/init.sh 里<a href="https://github.com/cilium/cilium/blob/v1.9.8/bpf/init.sh#L255">编译</a> 成 bpf 程序, 用 <a href="https://github.com/cilium/cilium/blob/v1.9.8/bpf/init.sh#L368">bpftool</a> 命令行加载进内核</li>
<li>bpf/init.sh 里有个 bpf_load 和 bpf_load_cgroups, 其中 bpf_load_cgroups 里有调用 bpftool, 而另一个没有, 了解一下另外一个逻辑是什么, 为啥不用调用也可以load, 只调用了一个 cilium-map-migrate</li>
</ul>
</li>
</ul>
</li>
<li>路由配置
<ul>
<li>cilium-agent 是个 rest http 服务, 以 ds 的形式跑在 node 上, 不同 node cilium-agent 之间会建立连接交换数据</li>
<li>cilium-agent 相当于是 k8s 节点信息 和 bpf 程序需要的 bpf map 数据之间的协议转换, 监听 node/service/pod 等信息, 并转换为 bpf map 数据, 写进 bpf map 数据里</li>
<li>cilium-agent 用 syscall bpf 系统调用, 将转换后的数据写进 bpf map 数据里</li>
<li>每次 syscall bpf 系统调用时, 第一个参数都会传入一个自定义的 <a href="https://github.com/cilium/cilium/blob/v1.9.8/pkg/bpf/bpf_linux.go#L68">const int</a> , 看<a href="https://github.com/cilium/cilium/blob/v1.9.8/pkg/bpf/bpf.go#L31">描述</a>是和c程序里的头程序对应的, 看样子是对应的, 可以看看系统调用是如何触发c程序处理对应的 const int 的</li>
</ul>
</li>
<li>流量处理
<ul>
<li>bpf 程序读取 bpf map 的值, 配置流量的转发, service/endpoint/lb 功能</li>
<li><code>TODO</code> bpf 程序, c 写的, 按理说应该可以单独调试, 找找调试的方法? 看看 cilium 项目里面是不是有对应的e2e调试/单元调试方法</li>
<li><code>TODO</code> 流量处理转发的过程待调试和研究, 应该需要看c代码里面的逻辑是如何转发的, 有没有绑定哪一个内核函数进行拦截处理流量, 或许就可以看出来cilium 都是如何转发流量的, 为什么性能比较好, 都做了哪些优化</li>
</ul>
</li>
<li>其他
<ul>
<li>cilium 貌似还有对 XDP 做支持</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="kube-proxy-v11717">kube-proxy (v1.17.17)</h1>
<ul>
<li>主要通过 proxyServer 里的 proxier 来响应 k8s 资源变化, 实现了多种接口: <code>k8s.io/kubernetes/pkg/proxy/config</code> 里的 <code>config.EndpointHandler</code>, <code>config.EndpointSlaceHandler</code>, <code>config.ServiceHandler</code>, <code>config.NodeHandler</code>, 可以代码查找下列 interface, 主要关注不同 proxier 对上述接口的实现</li>
<li>kube-proxy 实现了 3 种 proxier: <code>iptables</code>, <code>ipvs</code>, <code>userspace</code></li>
<li>从代码来看, ipvs 还分 <code>ipvs proxier</code> 和 <code>ipvs dual stack proxier</code>, 好像是对 ipv6 的支持</li>
<li>从 interface implement 来看, 还实现了一个 <code>win userspace proxier</code></li>
<li>iptables 实现:
<ul>
<li>通过 <code>pkg/proxy/iptables/proxier.go</code>.<code>syncProxyRules()</code> 执行 node 变化后 iptables 的同步</li>
<li>操作 iptables 通过 <code>pkg/util/iptables</code>.<code>runner</code> 实现了 <code>pkg/util/iptables</code>.<code>Interface</code></li>
<li><code>pkg/util/iptables</code>.<code>runner</code> 实际上是执行 <code>iptables</code> <code>ip6tables</code> 命令, runner 里还有一个实现了 <code>k8s.io/utils/exec</code>.<code>Interface</code> 的 <code>k8s.io/util/exec</code>.<code>executor</code>
<ul>
<li>其中还包括一个 <code>k8s.io/utils/exec</code>.<code>Cmd</code> 的接口抽象 <code>k8s.io/utils/exec</code>.<code>cmdWrapper</code>, 它包装了 <code>os/exec</code>.<code>Cmd</code></li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="scheduler-调度器">scheduler 调度器</h1>
<h2 id="default-scheduler">default scheduler</h2>
<ul>
<li>根据 filter 规则筛选出符合条件的 node (Predicates 阶段,算法), 再用 rating 规则给 node 打分 (Priority 阶段,算法), 最高分 node 作为调度结果
<ul>
<li>filter 规则有多种: 如判断 pod 资源 request 和 node 剩余资源是否符合, PV 所在的 node, 自定义 pod 资源, affinity 等等的维度</li>
</ul>
</li>
<li>调度结果是给 pod 的 spec.NodeName 设置 node 的名字</li>
<li>kubelet 找到有自己的 pod, 就会去部署?</li>
<li>kubelet 在部署 pod 前还会执行一个 admit 阶段(实际上是执行 predicates 阶段的逻辑), 重复检查确认, 判断是否符合 node 调度条件, 以免感知时间差过程中, node 状态发生了变化</li>
<li>kubelet admit 后, scheduler 会真正设置 nodename 到 pod 信息中, 这个步骤称为 &ldquo;bind&rdquo;</li>
<li>调度速度优化
<ul>
<li>cache 化, 调度前 scheduler 会将 node 的信息读取一份到内存, 避免计算过程需要重复获取 node 信息</li>
<li>无锁化, 调度过程需要出队 scheduler FIFO/Priority Queue, 以及更新 cache, 尽在获取任务和更新 cache 才需要获取锁</li>
<li>根据 node 并行化, 计算后再写到 scheduler cache 中</li>
</ul>
</li>
</ul>
<h2 id="default-scheduler-扩展机制">default scheduler 扩展机制</h2>
<ul>
<li>go plugins 形式在调度的各个阶段, 提供插件机制</li>
<li>阶段:
<ul>
<li>PreFilter</li>
<li>PostFilter</li>
<li>PostScoring</li>
<li>PreBind</li>
<li>PostBind</li>
</ul>
</li>
</ul>
<h1 id="service">service</h1>
<h2 id="clusterip">clusterip</h2>
<ul>
<li>通过 kube-proxy 监听 service 和对应 pod 变化, 在宿主机上更改 iptables / ipvs 配置, 实现 service 负载均衡功能
<ul>
<li>kube-proxy 普通模式通过 iptables &ndash;probiility 控制 service ip 到 pod 的流量</li>
<li>kube-proxy 还支持 &ndash;proxy-mode=ipvs (可以在 -n kube-system daemonSet kube-proxy 启动参数指定), 优化了 pod 数量对 iptables 管理的复杂性</li>
</ul>
</li>
<li>headless service (clusterip = None)
<ul>
<li>通过 kube-dns / 其他 dns 实现, 控制 service dns 解析返回的结果, 直接在 dns 记录里返回 pod ip</li>
</ul>
</li>
<li>nodeport
<ul>
<li>node 端口直接由 kube-proxy 进程监听</li>
<li>iptables, proxy-mode=ipvs 都没有看到对应的规则</li>
<li>疑似是用户态的代理?</li>
<li>service spec.exernalTraficPolicy: local, 指定 pod 回包时不用 SNAT 改为源 node 的 IP (client 请求的 node), 而是直接返回给 client</li>
</ul>
</li>
<li>loadbalancer
<ul>
<li>cloudprovider 转接层</li>
</ul>
</li>
<li>externalname
<ul>
<li>kube-dns 中将 service 域名解析成一个外部 cname</li>
</ul>
</li>
<li>其他
<ul>
<li>spec.externalIPs
<ul>
<li>访问配置的 ip 可以直接访问到 pod</li>
<li>需要 client 能访问 ip 可以直接访问到至少一个 node</li>
<li>实际上流量会先经过配置的 IP, 再代理到 node</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>ref:</p>
<ul>
<li><a href="https://time.geekbang.org/column/intro/116">张磊大大的 k8s 课程</a></li>
<li><a href="https://github.com/kubernetes/kubernetes.git">k8s 源码</a></li>
</ul>

                </div>
                
                <div class="post-comments">
                    
                </div>
                
            </div>
            <footer class="footer text-center">
<p>Copyright &copy; 2021 Hello, I&#39;m trainyao. -
<span class="credit">
	Powered by
	<a target="_blank" href="https://gohugo.io">Hugo</a>
	and
	<a target="_blank" href="https://github.com/LordMathis/hugo-theme-nix/">Nix</a> theme.
</span>
</p>
</footer>

        </div>
    </body>
